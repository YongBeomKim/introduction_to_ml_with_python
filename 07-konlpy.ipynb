{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pylab\n",
    "# %load_ext watermark\n",
    "# %watermark -v -p sklearn,konlpy,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KoNLPy, Mecab 을 활용한 한국어 분석**\n",
    "## **1 Naver 영화 리뷰 데이터 불러오기**\n",
    "0.4.5 버전부터 `Twitter` 클래스가 `Okt` 클래스로 변경 [open-korean-text](https://github.com/open-korean-text/open-korean-text) 프로젝트는 [twitter-korean-text](https://github.com/twitter/twitter-korean-text) 프로젝트의 공식 포크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('data/ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataSet : 150000\n",
      "Train Shape : [75173 74827]\n",
      "Test DataSet : 50000\n",
      "Test Shape : [24827 25173]\n"
     ]
    }
   ],
   "source": [
    "# 같은 방식으로 테스트 데이터를 읽습니다.\n",
    "text_train, y_train = df_train['document'].values, df_train['label'].values\n",
    "# 훈련 데이터와 테스트 데이터의 크기를 확인합니다.\n",
    "df_test   = pd.read_csv('data/ratings_test.txt', delimiter='\\t', keep_default_na=False)\n",
    "text_test = df_test['document'].values\n",
    "y_test    = df_test['label'].values\n",
    "p_text    = \"Train DataSet : {}\\nTrain Shape : {}\\nTest DataSet : {}\\nTest Shape : {}\"\n",
    "print(p_text.format(\n",
    "    len(text_train), np.bincount(y_train),\n",
    "    len(text_test),  np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 KoNLPy 모듈 활용하기**\n",
    "CoLab 에서 실행해본 결과 **Java 오류가 발생** 합니다.\n",
    "- GridSearchCV() 내부에서 Konlpy 를 실행하는데 있어서 Java 모듈이 충돌이 일어나는 듯.\n",
    "- 일반적인 Konlpy 모듈의 사용은 원활하게 작동하는데, **GridSearchCV 에서만 rt.jar 오류가** 발생\n",
    "- Mecab 을 실행하면 결과를 도출 가능하니 MeCab 으로 보완합니다 (결과값도 좋다!!)\n",
    "\n",
    "- `TfidfVectorizer` 의 토큰 파서를 대체하기 위해 `Okt` 클래스를 사용하는 함수를 만듭니다.\n",
    "- `min_df`, `ngram_range`, `C` 매개변수를 대상으로 그리드 서치를 수행합니다.\n",
    "\n",
    "사이킷런 0.22 버전에서 `LogisticRegression` 클래스의 `solver` 매개변수 기본값이 `liblinear`에서 `lbfgs`로 변경될 예정입니다. 사이킷런 0.20 버전에서 `solver` 매개변수를 지정하지 않는 경우 이에 대한 경고 메세지가 출력됩니다. 경고 메세지를 피하기 위해 `solver` 매개변수 값을 `liblinear`로 지정합니다.\n",
    "\n",
    "사이킷런 0.22 버전에서 `GridSearchCV` 클래스의 `cv` 매개변수 기본값이 3에서 5로 바뀔 예정입니다. 0.20 버전에서 `cv` 매개변수를 지정하지 않는 경우 이에 관한 경고 메세지가 출력됩니다. 경고 메세지를 피하기 위해 `cv` 매개변수 값을 명시적으로 3으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt_tag = Okt()\n",
    "# def okt_tokenizer(text):\n",
    "#     return okt_tag.morphs(text)\n",
    "# okt_param_grid = {'logisticregression__C': [0.1, 1, 10],\n",
    "#                   'tfidfvectorizer__min_df': [3, 5, 7],\n",
    "#                   'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],}\n",
    "# okt_pipe = make_pipeline(\n",
    "#     TfidfVectorizer(tokenizer = okt_tokenizer), \n",
    "#     LogisticRegression(solver = 'liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoLab 에서 실행해본 결과 Java 오류가 발생합니다.\n",
    "# GridSearchCV() 내부에서 Konlpy 를 실행하는데 있어서 Java 모듈이 충돌이 일어나는 듯.\n",
    "# 일반적인 Konlpy 모듈의 사용은 원활하게 작동하는데, GridSearchCV 에서만 rt.jar 오류가 발생\n",
    "# Mecab 을 실행하면 결과를 도출 가능하니 MeCab 으로 보완합니다 (결과값도 좋다!!)\n",
    "\n",
    "# %%time\n",
    "# okt_grid = GridSearchCV(okt_pipe, okt_param_grid, cv=3, n_jobs=-1)\n",
    "# okt_grid.fit(text_train[0:1000], y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_okt = okt_grid.best_estimator_.named_steps[\"tfidfvectorizer\"].transform(text_test)\n",
    "# score      = okt_grid.best_estimator_.named_steps[\"logisticregression\"].score(X_test_okt, y_test)\n",
    "# p_text = \"최상의 크로스 밸리데이션 점수: {:.3f}\\n최적의 크로스 밸리데이션 파라미터: {}\\n테스트 세트 점수: {:.3f}\"\n",
    "# print(p_text.format(\n",
    "#     okt_grid.best_score_, okt_grid.best_params_, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 Mecab 모듈 활용하기**\n",
    "- 병렬 처리를 위해서 `Mecab`을 사용하여 전체 데이터로 학습 시킵니다. \n",
    "- `Mecab`으로 토큰을 분할하는 함수를 만듭니다.\n",
    "- 최신 macOS Mojave에서는 `Mecab`에 필요한 jpype 라이브러리가 컴파일 오류가 발생 합니다. \n",
    "- 아래의 예제는 우분투에서 `n_jobs=1`을 사용해 실행한 내용 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 크로스 밸리데이션 점수: 0.870\n",
      "최적의 크로스 밸리데이션 파라미터:  {'logisticregression__C': 10, 'tfidfvectorizer__min_df': 3, 'tfidfvectorizer__ngram_range': (1, 3)}\n",
      "CPU times: user 45.5 s, sys: 2.15 s, total: 47.7 s\n",
      "Wall time: 29min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "def mecab_tokenizer(text):\n",
    "    return mecab.morphs(text)\n",
    "\n",
    "mecab_param_grid = {'tfidfvectorizer__min_df': [3, 5 ,7],\n",
    "              'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'logisticregression__C': [0.1, 1, 10, 100]}\n",
    "\n",
    "mecab_pipe = make_pipeline(TfidfVectorizer(tokenizer = mecab_tokenizer), \n",
    "                           LogisticRegression(solver = 'liblinear'))\n",
    "mecab_grid = GridSearchCV(mecab_pipe, mecab_param_grid, n_jobs=-1, cv=3)\n",
    "mecab_grid.fit(text_train, y_train)  # 그리드 서치를 수행합니다\n",
    "p_text = \"최상의 크로스 밸리데이션 점수: {:.3f}\\n최적의 크로스 밸리데이션 파라미터:\\n{}\"\n",
    "print(p_text.format(mecab_grid.best_score_, mecab_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수: 0.875\n"
     ]
    }
   ],
   "source": [
    "X_test_mecab = mecab_grid.best_estimator_.named_steps[\"tfidfvectorizer\"].transform(text_test)\n",
    "score = mecab_grid.best_estimator_.named_steps[\"logisticregression\"].score(X_test_mecab, y_test)\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
